{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dima-potapov-1/FDU/blob/main/AI_System_PRD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E0KVE2docrhC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PET36HCIcoD2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Product Requirements Document\n",
        "## Conversational Analytics System\n",
        "\n",
        "> **Version:** 1.4 (Draft)  \n",
        "> **Author:** Koen Rutten  \n",
        "> **Date:** February 17, 2026  \n",
        "> **Status:** Draft for Review  \n",
        "> **Objective:** O10 - PRD / Technical Design\n",
        "\n",
        "---\n",
        "\n",
        "## Document Structure\n",
        "\n",
        "This PRD is organized into two main sections:\n",
        "\n",
        "| Section | Purpose | Audience |\n",
        "|---------|---------|----------|\n",
        "| **Part A: Conceptual Framework** (Sections 1-7) | Architecture, principles, and requirements | Human reviewers |\n",
        "| **Part B: Implementation Details** (Appendices) | Schemas, interfaces, and agent instructions | Engineers & AI agents |\n",
        "\n",
        "---\n",
        "\n",
        "# PART A: CONCEPTUAL FRAMEWORK\n",
        "\n",
        "---\n",
        "\n",
        "# 1. Executive Summary\n",
        "\n",
        "## 1.1 Vision Statement\n",
        "\n",
        "Build a **context-aware, memory-driven, natural language analytics system** that enables analysts (human and agentic) to obtain **complete, accurate, and reliable** answers from enterprise data through conversational interfaces.\n",
        "\n",
        "### Staged Approach\n",
        "\n",
        "| Stage | Objective | Focus |\n",
        "|-------|-----------|-------|\n",
        "| **Stage 1** (Current) | Accurate, reliable query generation | Correct SQL from natural language; minimize silent errors |\n",
        "| **Stage 2** (Future) | Augmented judgment | Help users ask better questions; surface strategic relevance |\n",
        "\n",
        "**Stage 1** is the MVP focus. Stage 2 represents a future evolution where the system not only answers questions correctly but helps users identify which questions matter most given business objectives.\n",
        "\n",
        "## 1.2 Stage Boundaries\n",
        "\n",
        "### Stage 1: Read-Only Analytics (Current Focus)\n",
        "\n",
        "| Capability | Included | Notes |\n",
        "|------------|----------|-------|\n",
        "| SQL Generation | ✅ | SELECT queries only |\n",
        "| Query Validation | ✅ | Gotcha checks, schema validation |\n",
        "| Acceptance Flow | ✅ | User confirms before closing |\n",
        "| Disambiguation | ✅ | Clarifying questions when ambiguous |\n",
        "| Personal Memory | ✅ | User corrections applied locally |\n",
        "| Context Routing | ✅ | Match queries to entities |\n",
        "\n",
        "**Hard Gate:** Stage 1 **rejects any non-SELECT SQL**. INSERT, UPDATE, DELETE, DDL operations are not permitted regardless of autonomy level or user request.\n",
        "\n",
        "```\n",
        "IF sql_type NOT IN [\"SELECT\", \"WITH...SELECT\"]:\n",
        "    REJECT with message: \"Write operations are not supported in the current system version.\"\n",
        "```\n",
        "\n",
        "### Stage 2: Extended Capabilities (Future)\n",
        "\n",
        "| Capability | Status | Prerequisites |\n",
        "|------------|--------|---------------|\n",
        "| Write Operations | Future | Proven Stage 1 reliability, enhanced audit trail |\n",
        "| Strategic Judgment | Future | Business knowledge integration, OKR alignment |\n",
        "| Richer Autonomy | Future | Calibrated thresholds from Stage 1 data |\n",
        "| Proactive Insights | Future | Memory patterns, usage analysis |\n",
        "\n",
        "**Stage 2 unlocks when:**\n",
        "- Stage 1 production accuracy ≥85% sustained for 3 months\n",
        "- Error likelihood calibration validated\n",
        "- Business knowledge integration complete\n",
        "\n",
        "## 1.3 Core Value Proposition\n",
        "\n",
        "| Current State | Stage 1 Target | Stage 2 Vision |\n",
        "|---------------|----------------|----------------|\n",
        "| AI doesn't know our data → wrong queries | **Context Layer** provides curated knowledge → accurate queries | Context includes business objectives → strategically relevant queries |\n",
        "| Same mistakes repeat indefinitely | **Memory Layer** learns from corrections → continuous improvement | Memory includes user interests → personalized insights |\n",
        "| No guardrails on autonomous action | **Rules Layer** defines graduated autonomy → appropriate trust | Rules adapt to user risk tolerance |\n",
        "| Ad hoc query execution | **Orchestration Layer** manages request lifecycle → reliability | Orchestration prioritizes high-impact work |\n",
        "| Unknown error risk | **Error Likelihood Engine** quantifies risk → informed decisions | Risk includes business impact → cost-aware autonomy |\n",
        "\n",
        "## 1.4 Success Metrics\n",
        "\n",
        "| Metric | Current | Stage 1 Target | Measurement |\n",
        "|--------|---------|----------------|-------------|\n",
        "| Context Layer Routing Accuracy | 98.2% | ≥95% maintained | Automated eval suite |\n",
        "| Production Query Accuracy | Unknown | ≥85% | User feedback + correction rate |\n",
        "| Time to First Answer | Variable | <30s for routine queries | System logs |\n",
        "| Correction Learning Rate | 0% | 80% applied within 24h | Memory layer metrics |\n",
        "| User Acceptance Rate | N/A | ≥90% queries accepted without revision | User feedback |\n",
        "\n",
        "### Disambiguation Quality Metrics\n",
        "\n",
        "Rather than targeting a specific disambiguation *rate*, we measure disambiguation *quality*:\n",
        "\n",
        "| Metric | Definition | Target | Why It Matters |\n",
        "|--------|------------|--------|----------------|\n",
        "| **Clarification Precision** | % of clarifications that were actually needed (user chose non-default option) | ≥70% | Avoids unnecessary friction |\n",
        "| **Post-Clarification Acceptance** | % of queries accepted after clarification vs. rejected/revised | ≥85% | Clarification should help, not confuse |\n",
        "| **Incorrect-First-Answer Rate** | % of queries where first answer was wrong and required revision | ≤10% | Measures silent errors that disambiguation should have caught |\n",
        "\n",
        "**Interpretation:**\n",
        "- Low clarification precision → system is over-asking (annoying users)\n",
        "- Low post-clarification acceptance → clarification questions aren't helpful\n",
        "- High incorrect-first-answer rate → system is under-asking (missing ambiguity)\n",
        "\n",
        "---\n",
        "\n",
        "# 2. System Architecture\n",
        "\n",
        "## 2.1 High-Level Architecture\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────────────────────────────────────┐\n",
        "│                            ORCHESTRATION LAYER                                    │\n",
        "│                                                                                   │\n",
        "│   INTAKE → SCOPE → EXECUTE → DELIVER → ACCEPT → CLOSE                           │\n",
        "│                                                                                   │\n",
        "│   [Error Likelihood + Expected Cost calculated at each decision point]           │\n",
        "└────────────────────────────────┬────────────────────────────────────────────────┘\n",
        "                                 │\n",
        "         ┌───────────────────────┼───────────────────────┐\n",
        "         │                       │                       │\n",
        "         ▼                       ▼                       ▼\n",
        "┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐\n",
        "│  CONTEXT LAYER  │   │   RULES LAYER   │   │  MEMORY LAYER   │\n",
        "│                 │   │                 │   │                 │\n",
        "│ Data Knowledge: │   │ • Permissions   │   │ • Corrections   │\n",
        "│ • Entities      │   │ • Autonomy      │   │ • Preferences   │\n",
        "│ • Metrics       │   │ • Thresholds    │   │ • Work History  │\n",
        "│ • Gotchas       │   │ • Escalation    │   │ • Relationships │\n",
        "│ • Lineage       │   │ • PII Rules     │   │ • Learnings     │\n",
        "│                 │   │                 │   │                 │\n",
        "│ Business        │   │ Risk Tolerance: │   │ User Profile:   │\n",
        "│ Knowledge:      │   │ • Per-user      │   │ • Interests     │\n",
        "│ • OKRs          │   │   settings      │   │ • Authority     │\n",
        "│ • Strategy docs │   │ • Per-request   │   │ • Role context  │\n",
        "│ • Projects      │   │   overrides     │   │                 │\n",
        "│ • Domain guides │   │                 │   │                 │\n",
        "└─────────────────┘   └─────────────────┘   └─────────────────┘\n",
        "         │                       │                       │\n",
        "         └───────────────────────┼───────────────────────┘\n",
        "                                 │\n",
        "                                 ▼\n",
        "┌─────────────────────────────────────────────────────────────────────────────────┐\n",
        "│                        EXECUTION & VALIDATION LAYER                               │\n",
        "│                                                                                   │\n",
        "│   SQL Generation → Gotcha Validation → Execute → Result Presentation             │\n",
        "└────────────────────────────────┬────────────────────────────────────────────────┘\n",
        "                                 │\n",
        "                                 ▼\n",
        "┌─────────────────────────────────────────────────────────────────────────────────┐\n",
        "│                        EVALUATION & FEEDBACK LAYER                                │\n",
        "│                                                                                   │\n",
        "│   Query-Level Evals ← Component-Level Evals ← System-Level Evals                 │\n",
        "│                              ↓                                                    │\n",
        "│                    Correction Classification → Layer Updates                      │\n",
        "└─────────────────────────────────────────────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "## 2.2 Component Differentiation\n",
        "\n",
        "### Context Layer vs Memory Layer\n",
        "\n",
        "These layers serve distinct but complementary purposes:\n",
        "\n",
        "| Aspect | Context Layer | Memory Layer |\n",
        "|--------|---------------|--------------|\n",
        "| **Scope** | Shared, organizational knowledge | User-specific, session-specific |\n",
        "| **Content** | Data schemas, business objectives, domain guides | Corrections, preferences, conversation history |\n",
        "| **Persistence** | Long-lived, curated | Evolving, accumulated |\n",
        "| **Access** | Available to all actors | Filtered by user/session |\n",
        "| **Updates** | Deliberate, reviewed | Continuous, automated |\n",
        "\n",
        "**Context Layer** answers: \"What does the organization know about this data and domain?\"\n",
        "\n",
        "**Memory Layer** answers: \"What does the system remember about this user and their past interactions?\"\n",
        "\n",
        "### What Makes Context Layer More Than a Semantic Layer?\n",
        "\n",
        "Traditional semantic layers focus on **data definitions** (entities, metrics, joins). Our Context Layer expands to include:\n",
        "\n",
        "| Traditional Semantic Layer | Extended Context Layer |\n",
        "|---------------------------|------------------------|\n",
        "| Entity definitions | Entity definitions |\n",
        "| Metric calculations | Metric calculations |\n",
        "| Join paths | Join paths |\n",
        "| — | **Business objectives** (OKRs, strategy) |\n",
        "| — | **Domain guides** (conventions, gotchas) |\n",
        "| — | **Project context** (what matters now) |\n",
        "| — | **Organizational artifacts** (qualitative studies, competitive intel) |\n",
        "\n",
        "This extension enables **Stage 2** (augmented judgment) by connecting data questions to business priorities.\n",
        "\n",
        "## 2.3 Data Access Model\n",
        "\n",
        "**Decision:** The LLM can see query results to enable summarization and (Stage 2) trend analysis. PII scrubbing is applied on the backend before results reach the LLM.\n",
        "\n",
        "This enables richer functionality while managing data sensitivity through existing infrastructure controls.\n",
        "\n",
        "---\n",
        "\n",
        "# 3. Design Principles\n",
        "\n",
        "## P1: Compound, Not Monolithic\n",
        "\n",
        "**Principle:** The system is an orchestrated set of components, not a single agent.\n",
        "\n",
        "**Rationale:**\n",
        "- Each component can evolve independently\n",
        "- Clear ownership enables accountability\n",
        "- Failures are isolated and debuggable\n",
        "- Teams can work in parallel\n",
        "\n",
        "## P2: Explicit Interfaces Over Implicit Coupling\n",
        "\n",
        "**Principle:** Components interact through defined contracts (registries), not assumptions.\n",
        "\n",
        "**What are Registries?**\n",
        "\n",
        "| Registry | Purpose | Contents |\n",
        "|----------|---------|----------|\n",
        "| **Agent Registry** | Discover and route to available agents/models | Agent capabilities, cost profiles, latency characteristics |\n",
        "| **Data Registry** | Discover and understand available data | Entity definitions, schemas, owners, freshness |\n",
        "\n",
        "**Why explicit interfaces are preferable to implicit coupling:**\n",
        "\n",
        "| Implicit Coupling | Explicit Interfaces |\n",
        "|-------------------|---------------------|\n",
        "| Component A assumes Component B's behavior | Component A reads B's contract |\n",
        "| Changes to B silently break A | Contract changes are versioned and communicated |\n",
        "| Testing requires full system | Components tested in isolation with mock contracts |\n",
        "| Ownership unclear | Contract has explicit owner |\n",
        "| Debugging requires tracing through system | Interface violations caught at boundaries |\n",
        "\n",
        "## P3: Meaning from Code\n",
        "\n",
        "**Principle:** Context is enriched from dbt/pipeline code, not only manual documentation.\n",
        "\n",
        "**What this means:**\n",
        "\n",
        "The dbt codebase contains rich semantic information that can be automatically extracted:\n",
        "\n",
        "| Source | Extractable Meaning |\n",
        "|--------|---------------------|\n",
        "| Model SQL | Business logic, transformations, scope |\n",
        "| Model config | Materialization, freshness guarantees |\n",
        "| Column descriptions | Semantic definitions |\n",
        "| Tests | Data quality constraints |\n",
        "| Exposures | Downstream dependencies |\n",
        "| Sources | Upstream data lineage |\n",
        "\n",
        "**How we intend to achieve automated meaning extraction:**\n",
        "\n",
        "1. **Parse dbt manifest.json** — Extract model metadata, column info, tests\n",
        "2. **Analyze model SQL** — Identify join patterns, filter conditions, aggregations\n",
        "3. **Extract from YAML docs** — Pull descriptions, owners, tags\n",
        "4. **Infer from usage** — Common query patterns, frequently joined entities\n",
        "\n",
        "**Context Refresh Latency:**\n",
        "\n",
        "Context Layer updates are **CI/CD-driven**:\n",
        "- When dbt models are merged/deployed, the manifest is re-parsed\n",
        "- Context Layer is updated within minutes of deployment\n",
        "- No runtime parsing overhead on each query\n",
        "\n",
        "**Risk:** If a dbt model changes and the Context Layer hasn't refreshed, the agent may use stale schema info, causing errors. Mitigations:\n",
        "- CI/CD pipeline includes Context Layer refresh as a post-deploy step\n",
        "- Context Layer includes schema version/timestamp for staleness detection\n",
        "- High-novelty queries trigger a freshness check\n",
        "\n",
        "This is a **Stage 2** enhancement. For Stage 1, we focus on optimizing manual model documentation for both agents and humans.\n",
        "\n",
        "## P4: Production-in-the-Loop\n",
        "\n",
        "**Principle:** Evaluations are fed by real query patterns and corrections.\n",
        "\n",
        "**Why this matters:**\n",
        "\n",
        "| Synthetic Evals Only | Production-in-the-Loop |\n",
        "|----------------------|------------------------|\n",
        "| Test what we think matters | Test what actually matters |\n",
        "| Optimized for imagined scenarios | Optimized for real usage |\n",
        "| Blind to distribution shift | Detects when reality changes |\n",
        "| No feedback on actual accuracy | Continuous accuracy measurement |\n",
        "\n",
        "**The production-benchmark gap is real:** Research shows state-of-the-art models achieve ~91% on simple benchmarks but ~21% on real enterprise queries (Spider 2.0). Our evals must reflect production reality.\n",
        "\n",
        "## P5: Graduated Autonomy\n",
        "\n",
        "**Principle:** Risk thresholds determine when to proceed, seek confirmation, or block.\n",
        "\n",
        "**Risk = Probability × Cost**\n",
        "\n",
        "Autonomy decisions should consider both:\n",
        "- **Error Likelihood** — Probability the query is wrong\n",
        "- **Expected Cost** — Impact if the query is wrong\n",
        "\n",
        "See Section 5 for detailed autonomy model.\n",
        "\n",
        "## P6: Consistent Interfaces, Optimized Presentation\n",
        "\n",
        "**Principle:** Components expose consistent interfaces; presentation is optimized per actor type.\n",
        "\n",
        "**Clarification:** \"Same interface\" means the underlying data contracts are consistent. However, **how information is presented** may differ:\n",
        "\n",
        "| Aspect | Human Presentation | Agent Presentation |\n",
        "|--------|-------------------|-------------------|\n",
        "| Format | Natural language, visualizations | Structured YAML/JSON |\n",
        "| Verbosity | Concise summaries | Complete details |\n",
        "| Navigation | Interactive, drill-down | Direct access |\n",
        "| Context | Highlighted relevance | Full context window |\n",
        "\n",
        "The **transformation layer** adapts consistent underlying data to optimal presentation per actor type.\n",
        "\n",
        "---\n",
        "\n",
        "# 4. Context Layer\n",
        "\n",
        "## 4.1 Purpose\n",
        "\n",
        "Provide structured knowledge that enables accurate query generation and (in Stage 2) strategically relevant insights.\n",
        "\n",
        "## 4.2 Content Categories\n",
        "\n",
        "### 4.2.1 Data Knowledge (Stage 1 Focus)\n",
        "\n",
        "| Category | Description | Current State |\n",
        "|----------|-------------|---------------|\n",
        "| **Entity definitions** | Tables, columns, types, distributions | ✅ 36+ entities documented |\n",
        "| **Metric calculations** | Canonical formulas, gotchas | ⚠️ Partial (embedded in entities) |\n",
        "| **Join paths** | How entities relate | ✅ Documented |\n",
        "| **Gotchas** | Silent error patterns | ✅ 11+ documented |\n",
        "| **Domain guides** | Conventions per domain | ✅ GTM, Revenue, Finance, Marketing |\n",
        "\n",
        "### 4.2.2 Business Knowledge (Stage 2 Focus)\n",
        "\n",
        "| Category | Description | Current State |\n",
        "|----------|-------------|---------------|\n",
        "| **OKRs** | Company/team objectives | ❌ Not integrated |\n",
        "| **Strategy documents** | Corporate priorities | ❌ Not integrated |\n",
        "| **Project descriptions** | Current initiatives | ⚠️ Exists in discussion/ folder |\n",
        "| **Qualitative studies** | User research, insights | ❌ Not integrated |\n",
        "| **Competitive intelligence** | Market context | ❌ Not integrated |\n",
        "\n",
        "**Note:** Business knowledge integration is a Stage 2 objective. The mechanism for integration (direct indexing, RAG, summarization) is to be determined.\n",
        "\n",
        "## 4.3 Domain Coverage\n",
        "\n",
        "The current `analytics-context` repo focuses on specific domains. Coverage decisions remain open:\n",
        "\n",
        "| Domain | Current Status | Priority |\n",
        "|--------|---------------|----------|\n",
        "| Growth | ✅ Covered | High |\n",
        "| Finance | ✅ Covered | High |\n",
        "| Revenue | ✅ Covered | High |\n",
        "| Marketing | ✅ Covered | Medium |\n",
        "| **Product Analytics** | ❌ Not covered | **High (MVP focus)** |\n",
        "| Support | ❌ Not covered | Medium |\n",
        "| Engineering | ❌ Not covered | Low |\n",
        "\n",
        "**Decision needed:** How do we prioritize and resource domain coverage expansion?\n",
        "\n",
        "## 4.4 Enhancement Roadmap\n",
        "\n",
        "| Priority | Enhancement | Stage | Notes |\n",
        "|----------|-------------|-------|-------|\n",
        "| P1 | Add Product Analytics domain guide | 1 | MVP focus area |\n",
        "| P1 | Optimize model documentation for agents + humans | 1 | Replace key_dimension_registry focus |\n",
        "| P2 | Establish domain coverage strategy | 1 | Decide prioritization |\n",
        "| P3 | dbt code enrichment pipeline | 2 | Automated meaning extraction |\n",
        "| P3 | Business knowledge integration | 2 | OKRs, strategy docs |\n",
        "\n",
        "---\n",
        "\n",
        "# 5. Rules Layer\n",
        "\n",
        "## 5.1 Purpose\n",
        "\n",
        "Define what actions are permitted, by whom, under what conditions, and with what level of autonomy.\n",
        "\n",
        "## 5.2 Autonomy Model\n",
        "\n",
        "### 5.2.1 Risk-Based Autonomy\n",
        "\n",
        "Autonomy level is determined by:\n",
        "\n",
        "```\n",
        "Risk Score = f(Error Likelihood, Expected Cost)\n",
        "```\n",
        "\n",
        "Where:\n",
        "- **Error Likelihood** = Probability the output is incorrect (see Section 6)\n",
        "- **Expected Cost** = Estimated impact if the output is wrong\n",
        "\n",
        "### 5.2.2 Expected Cost Factors\n",
        "\n",
        "| Factor | Description | How to Assess |\n",
        "|--------|-------------|---------------|\n",
        "| **Decision criticality** | How important is this decision? | User indicates; infer from context |\n",
        "| **Reversibility** | Can mistakes be undone? | Query type (read vs write) |\n",
        "| **Audience** | Who sees the results? | User indicates; infer from request |\n",
        "| **Time sensitivity** | Is there urgency? | User indicates |\n",
        "\n",
        "**Capturing Expected Cost:**\n",
        "\n",
        "Since we lack empirical data on error costs, we propose:\n",
        "\n",
        "1. **Ask users** to indicate criticality per request (optional field)\n",
        "2. **Infer from context** (e.g., \"for the board meeting\" = high stakes)\n",
        "3. **Learn from feedback** — track which errors users flag as serious\n",
        "\n",
        "### 5.2.3 Autonomy Levels\n",
        "\n",
        "| Level | Name | Behavior | When Used |\n",
        "|-------|------|----------|-----------|\n",
        "| **5** | Full Autonomy | Execute and close | Low risk, routine query |\n",
        "| **4** | Execute & Notify | Execute, inform stakeholders | Low-medium risk, notable query |\n",
        "| **3** | Execute & Confirm | Execute, await user confirmation before considering complete | Medium risk, user accepts or revises |\n",
        "| **2** | Recommend Only | Generate recommendation, user executes | High risk or user preference |\n",
        "| **1** | Human Only | Flag for human handling | Very high risk or policy requirement |\n",
        "\n",
        "**Clarification: Level 3 vs Level 4**\n",
        "\n",
        "- **Level 4 (Notify):** System executes and sends notification. No response required. Useful for audit trail.\n",
        "- **Level 3 (Confirm):** System executes but the request remains \"pending acceptance\" until user confirms. User must explicitly accept or revise.\n",
        "\n",
        "### 5.2.4 User Risk Tolerance\n",
        "\n",
        "Users can set preferences that influence autonomy decisions:\n",
        "\n",
        "| Preference | Effect |\n",
        "|------------|--------|\n",
        "| \"I prefer to review all queries\" | Never use Level 5 |\n",
        "| \"I trust routine queries\" | Use Level 5 for low complexity |\n",
        "| \"Always confirm financial data\" | Use Level 3+ for finance domain |\n",
        "\n",
        "**Per-request overrides:** Users can always specify \"please confirm before executing\" or \"just do it\" on individual requests.\n",
        "\n",
        "### 5.2.5 Mandatory Validation Threshold\n",
        "\n",
        "When risk exceeds a threshold (to be calibrated), manual validation is **always required** regardless of user preferences:\n",
        "\n",
        "```\n",
        "IF (error_likelihood × expected_cost) > MANDATORY_REVIEW_THRESHOLD:\n",
        "    autonomy_level = min(autonomy_level, 3)  # At most \"Execute & Confirm\"\n",
        "```\n",
        "\n",
        "### 5.2.6 Stage 1 Operational Safeguards\n",
        "\n",
        "Stage 1 operates with minimal but essential safeguards:\n",
        "\n",
        "| Safeguard | Implementation | Rationale |\n",
        "|-----------|----------------|-----------|\n",
        "| **Query Type Allowlist** | Only SELECT queries permitted | Stage 1 is read-only by design |\n",
        "| **Schema Whitelist** | User RBAC determines accessible schemas | Prevent unauthorized data access |\n",
        "| **Audit Logging** | All queries logged with context | Traceability and debugging |\n",
        "\n",
        "**Hard Gate: Non-SELECT Rejection**\n",
        "\n",
        "```\n",
        "IF sql_type NOT IN [\"SELECT\", \"WITH...SELECT\"]:\n",
        "    REJECT immediately\n",
        "    Response: \"Write operations are not supported. Stage 1 is read-only.\"\n",
        "```\n",
        "\n",
        "This is not a \"high-cost trigger\" — it's a hard boundary. Write operations are a Stage 2 capability.\n",
        "\n",
        "### 5.2.7 Policy-Based Triggers (Stage 1)\n",
        "\n",
        "Within read-only operations, certain patterns still warrant elevated review:\n",
        "\n",
        "| Trigger | Condition | Minimum Level | Rationale |\n",
        "|---------|-----------|---------------|-----------|\n",
        "| **Resource Intensity** | EXPLAIN plan estimates >100GB scan or >10min runtime | Level 3 (Confirm) | Warehouse protection |\n",
        "| **Cross-Domain Joins** | Query joins entities from 3+ domains | Level 4 (Notify) | Complex, error-prone |\n",
        "| **Sensitive Tables** | Query touches tables tagged `sensitive` | Level 4 (Notify) | Awareness for sensitive data |\n",
        "\n",
        "These triggers are defined in `rules/autonomy.yaml` and apply within Stage 1's read-only scope.\n",
        "\n",
        "---\n",
        "\n",
        "# 6. Error Likelihood Engine\n",
        "\n",
        "## 6.1 Purpose\n",
        "\n",
        "Calculate the probability of error to inform autonomy decisions and trigger disambiguation.\n",
        "\n",
        "## 6.2 Formula\n",
        "\n",
        "```\n",
        "Error Likelihood = (\n",
        "    w_complexity × complexity_score +\n",
        "    w_source     × source_risk_score +\n",
        "    w_novelty    × novelty_score +\n",
        "    w_ambiguity  × ambiguity_score\n",
        ")\n",
        "```\n",
        "\n",
        "### Bootstrap Weights (Equal)\n",
        "\n",
        "```\n",
        "w_complexity = 0.25\n",
        "w_source     = 0.25\n",
        "w_novelty    = 0.25\n",
        "w_ambiguity  = 0.25\n",
        "```\n",
        "\n",
        "**This is an explicit bootstrap policy.** Equal weights are used because we lack production data to inform better weights.\n",
        "\n",
        "### Weight Calibration Plan\n",
        "\n",
        "| Phase | Timing | Action |\n",
        "|-------|--------|--------|\n",
        "| **Bootstrap** | Launch | Equal weights (0.25 each) |\n",
        "| **Observation** | Months 1-2 | Collect correction/failure data tagged by factor |\n",
        "| **First Calibration** | Month 3 | Analyze which factors correlate with actual errors |\n",
        "| **Recalibration** | Monthly thereafter | Update weights based on trailing 30-day error patterns |\n",
        "\n",
        "**Calibration method:**\n",
        "```\n",
        "For each failed query (user rejected or corrected):\n",
        "  1. Record the factor scores at time of query\n",
        "  2. Identify which factors were elevated vs. baseline\n",
        "  3. Weight factors that were elevated in failures more heavily\n",
        "  \n",
        "New weights = normalize(\n",
        "  baseline_weight + learning_rate × (factor_failure_correlation)\n",
        ")\n",
        "```\n",
        "\n",
        "**Constraint:** No single weight can exceed 0.5 or fall below 0.1 to prevent over-fitting to noise.\n",
        "\n",
        "## 6.3 Factor Definitions and Computation\n",
        "\n",
        "| Factor | What It Measures | High Score Means |\n",
        "|--------|------------------|------------------|\n",
        "| **Complexity** | Query structural complexity (joins, CTEs, window functions) | More ways to make mistakes |\n",
        "| **Source Risk** | Data source reliability (documentation, test coverage, freshness) | Less trustworthy data |\n",
        "| **Novelty** | Dissimilarity to past successful queries | Uncharted territory |\n",
        "| **Ambiguity** | Multiple interpretations possible (column names, metrics, entities) | User intent unclear |\n",
        "\n",
        "### 6.3.1 Complexity Score (Deterministic)\n",
        "\n",
        "Computed via **AST (Abstract Syntax Tree) parsing** of the generated SQL:\n",
        "\n",
        "```\n",
        "complexity = normalize(\n",
        "    num_joins × 0.25 +\n",
        "    num_ctes × 0.20 +\n",
        "    has_window_functions × 0.20 +\n",
        "    num_subqueries × 0.20 +\n",
        "    num_aggregations × 0.15\n",
        ")\n",
        "```\n",
        "\n",
        "This is deterministic and computed after SQL generation.\n",
        "\n",
        "### 6.3.2 Source Risk Score (Deterministic)\n",
        "\n",
        "Computed from metadata in the Context Layer:\n",
        "\n",
        "```\n",
        "source_risk = 1 - average([\n",
        "    entity.documentation_completeness,  # % of columns documented\n",
        "    entity.test_coverage,               # % of columns with tests\n",
        "    entity.freshness_score,             # How recently validated\n",
        "    entity.owner_responsiveness         # SLA for owner response\n",
        "])\n",
        "```\n",
        "\n",
        "### 6.3.3 Novelty Score (Semantic Similarity)\n",
        "\n",
        "Computed via **semantic similarity to the Golden Query Set** (verified past queries):\n",
        "\n",
        "```\n",
        "novelty = 1 - max_similarity(\n",
        "    query_embedding,\n",
        "    golden_query_embeddings  # Verified correct queries\n",
        ")\n",
        "```\n",
        "\n",
        "If the query is very different from any verified past query, novelty is high.\n",
        "\n",
        "### 6.3.4 Ambiguity Score (Retrieval Conflict + Optional LLM Confidence)\n",
        "\n",
        "Ambiguity is the hardest to compute deterministically. We use a primary signal with an optional enhancement.\n",
        "\n",
        "**Primary Signal: Retrieval Conflict + Schema Collision**\n",
        "\n",
        "These heuristics are always available:\n",
        "\n",
        "```\n",
        "# Retrieval conflict: similar scores but conflicting definitions\n",
        "retrieval_spread = std_dev(top_n_relevance_scores)\n",
        "retrieval_conflict = detect_conflicting_definitions(top_n_chunks)\n",
        "ambiguity_retrieval = retrieval_conflict × (1 - retrieval_spread)\n",
        "\n",
        "# Schema collision: multiple columns/tables match the same term\n",
        "schema_matches = count_matching_columns(query_terms)\n",
        "ambiguity_schema = normalize(schema_matches - 1)  # 0 if unique match\n",
        "\n",
        "# Combined heuristic\n",
        "ambiguity_heuristic = 0.6 × ambiguity_retrieval + 0.4 × ambiguity_schema\n",
        "```\n",
        "\n",
        "**Optional Enhancement: LLM Log Probabilities**\n",
        "\n",
        "If the LLM API provides log probabilities (not all do):\n",
        "\n",
        "```\n",
        "ambiguity_llm = 1 - average(log_probs[key_entity_tokens])\n",
        "```\n",
        "\n",
        "**Combined (when logprobs available):**\n",
        "```\n",
        "ambiguity = 0.5 × ambiguity_heuristic + 0.5 × ambiguity_llm\n",
        "```\n",
        "\n",
        "**Fallback (when logprobs unavailable):**\n",
        "```\n",
        "ambiguity = ambiguity_heuristic\n",
        "```\n",
        "\n",
        "| LLM Provider | Logprobs Available | Ambiguity Calculation |\n",
        "|--------------|--------------------|-----------------------|\n",
        "| OpenAI (GPT-4) | ✅ Yes | Hybrid (heuristic + logprobs) |\n",
        "| Anthropic (Claude) | ❌ No | Heuristic only |\n",
        "| Azure OpenAI | ✅ Yes | Hybrid |\n",
        "| Local models | Varies | Check per deployment |\n",
        "\n",
        "The heuristic-only approach is still effective — it catches the most common ambiguity patterns (multiple matching columns, conflicting definitions). Logprobs provide refinement, not a fundamental capability.\n",
        "\n",
        "## 6.4 Thresholds and Actions\n",
        "\n",
        "| Error Likelihood | Expected Cost: Low | Expected Cost: High |\n",
        "|------------------|-------------------|---------------------|\n",
        "| < 0.3 | Level 5 (Full) | Level 4 (Notify) |\n",
        "| 0.3 - 0.5 | Level 4 (Notify) | Level 3 (Confirm) |\n",
        "| 0.5 - 0.7 | Level 3 (Confirm) | Level 2 (Recommend) |\n",
        "| ≥ 0.7 | Level 2 (Recommend) | Level 1 (Human) |\n",
        "\n",
        "---\n",
        "\n",
        "# 7. Evaluation Framework\n",
        "\n",
        "## 7.1 Evaluation Hierarchy\n",
        "\n",
        "Evaluations operate at three levels:\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────────────┐\n",
        "│                 SYSTEM-LEVEL EVALS                       │\n",
        "│   Does the overall system meet user needs?               │\n",
        "│   Metrics: User satisfaction, task completion rate       │\n",
        "└────────────────────────────┬────────────────────────────┘\n",
        "                             │\n",
        "┌────────────────────────────┴────────────────────────────┐\n",
        "│               COMPONENT-LEVEL EVALS                      │\n",
        "│   Does each component perform its function?              │\n",
        "│   Metrics: Routing accuracy, autonomy calibration        │\n",
        "└────────────────────────────┬────────────────────────────┘\n",
        "                             │\n",
        "┌────────────────────────────┴────────────────────────────┐\n",
        "│                 QUERY-LEVEL EVALS                        │\n",
        "│   Is this specific query correct?                        │\n",
        "│   Metrics: SQL correctness, result accuracy              │\n",
        "└─────────────────────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "## 7.2 Current State\n",
        "\n",
        "| Level | Eval Type | Status |\n",
        "|-------|-----------|--------|\n",
        "| Query | Context layer routing | ✅ 178 questions, 98.2% accuracy |\n",
        "| Query | SQL correctness | ❌ No ground truth dataset |\n",
        "| Component | Memory effectiveness | ❌ Not implemented |\n",
        "| Component | Autonomy calibration | ❌ Not implemented |\n",
        "| System | End-to-end accuracy | ❌ No production measurement |\n",
        "| System | User satisfaction | ❌ No feedback collection |\n",
        "\n",
        "## 7.3 Eval Development Priority\n",
        "\n",
        "### Stage 1: Foundation\n",
        "\n",
        "1. **Production query logging** — Capture real queries to understand distribution\n",
        "2. **User feedback collection** — Thumbs up/down, corrections\n",
        "3. **Ground truth dataset** — Curated set of queries with verified correct SQL\n",
        "\n",
        "### Stage 2: Calibration\n",
        "\n",
        "4. **Error likelihood validation** — Do high-likelihood queries actually fail more?\n",
        "5. **Autonomy calibration** — Are thresholds set correctly?\n",
        "6. **Component isolation testing** — Each layer tested independently\n",
        "\n",
        "### Informing Golden Evals with Error Likelihood\n",
        "\n",
        "The ground truth dataset should be **informed by error likelihood factors**:\n",
        "\n",
        "| Factor | Implication for Eval Coverage |\n",
        "|--------|------------------------------|\n",
        "| High complexity | Include multi-join, CTE, window function queries |\n",
        "| Source risk | Include queries on poorly-documented tables |\n",
        "| Novelty | Include unusual query patterns |\n",
        "| Ambiguity | Include queries with ambiguous column names |\n",
        "\n",
        "This ensures evals cover the **riskiest** scenarios, not just easy cases.\n",
        "\n",
        "---\n",
        "\n",
        "# 8. Orchestration Layer\n",
        "\n",
        "## 8.1 Purpose\n",
        "\n",
        "Manage the full request lifecycle from intake to closure, including user acceptance.\n",
        "\n",
        "## 8.2 Request Lifecycle\n",
        "\n",
        "```\n",
        "INTAKE → SCOPE → PLAN → EXECUTE → DELIVER → ACCEPT → CLOSE\n",
        "                  │                            ↑\n",
        "                  │                   User confirms or\n",
        "                  │                   requests revision\n",
        "                  ▼\n",
        "           [EXPLAIN Plan Check]\n",
        "           If resource-intensive → Halt, request confirmation\n",
        "```\n",
        "\n",
        "### Stage Gates\n",
        "\n",
        "| Stage | Entry | Exit | Key Decision |\n",
        "|-------|-------|------|--------------|\n",
        "| **INTAKE** | Request received | Request parsed | Is request valid? |\n",
        "| **SCOPE** | Parsed request | Entities identified | Error likelihood calculated |\n",
        "| **PLAN** | SQL generated | Plan validated | Is execution safe? (resource check) |\n",
        "| **EXECUTE** | Plan approved | SQL executed | Autonomy level applied |\n",
        "| **DELIVER** | Results available | Results presented | Presentation complete |\n",
        "| **ACCEPT** | Results presented | User accepts OR revises | **User acceptance required** |\n",
        "| **CLOSE** | Acceptance received | Request closed | Feedback logged |\n",
        "\n",
        "### PLAN Stage: Resource Safety Check\n",
        "\n",
        "Before execution, the system runs an `EXPLAIN` (dry run) on the generated SQL:\n",
        "\n",
        "```sql\n",
        "EXPLAIN <generated_sql>\n",
        "```\n",
        "\n",
        "If the estimated resource cost exceeds thresholds:\n",
        "\n",
        "| Metric | Threshold | Action |\n",
        "|--------|-----------|--------|\n",
        "| Estimated scan size | >100GB | Halt, request confirmation |\n",
        "| Estimated runtime | >10 minutes | Halt, request confirmation |\n",
        "| Estimated row count | >100M rows | Warn, proceed with caution |\n",
        "\n",
        "This prevents the AI from accidentally overwhelming the data warehouse, even if the semantic risk was calculated as low.\n",
        "\n",
        "### User Acceptance\n",
        "\n",
        "**User acceptance is always required before closing a request.**\n",
        "\n",
        "| Acceptance Type | Mechanism | When Used |\n",
        "|-----------------|-----------|-----------|\n",
        "| **Explicit** | User clicks \"Accept\" or \"Looks good\" | Level 3 and below |\n",
        "| **Implicit** | User takes action on results (downloads, shares) | Level 4-5 |\n",
        "| **Timeout** | No response within window → auto-accept with flag | Level 5 only |\n",
        "\n",
        "For Level 1-3, explicit acceptance is required. For Level 4-5, implicit acceptance (user engagement with results) or timeout is acceptable.\n",
        "\n",
        "### Timeout Handling\n",
        "\n",
        "Different autonomy levels have different timeout policies:\n",
        "\n",
        "| Level | Timeout Policy | On Timeout |\n",
        "|-------|----------------|------------|\n",
        "| **Level 5** | 24 hours | Auto-accept, close request |\n",
        "| **Level 4** | 48 hours | Auto-accept, close request |\n",
        "| **Level 3** | 72 hours | **Expire request, notify user** |\n",
        "| **Level 2** | 7 days | Expire recommendation, notify user |\n",
        "| **Level 1** | No timeout | Remains open until human handles |\n",
        "\n",
        "**Level 3 Timeout Behavior (Execute & Confirm):**\n",
        "\n",
        "When a Level 3 request times out without user confirmation:\n",
        "\n",
        "1. Request is marked as **\"Abandoned\"** (not auto-accepted)\n",
        "2. User receives notification: *\"Your query from [date] timed out without confirmation. Results were not finalized. Please resubmit if still needed.\"*\n",
        "3. Any actions taken are flagged for potential rollback (if applicable)\n",
        "4. Query is logged with `outcome: abandoned` for eval purposes\n",
        "\n",
        "**Rationale:** Level 3 requests are medium-risk. Auto-accepting them on timeout would defeat the purpose of requiring confirmation. Expiring with notification ensures users are aware without creating orphan requests.\n",
        "\n",
        "---\n",
        "\n",
        "# 9. Memory Layer\n",
        "\n",
        "## 9.1 Purpose\n",
        "\n",
        "Persist user-specific learnings to enable personalization and continuous improvement.\n",
        "\n",
        "## 9.2 Memory Categories\n",
        "\n",
        "| Category | Contents | Retention |\n",
        "|----------|----------|-----------|\n",
        "| **Corrections** | What the user fixed | Permanent (→ may promote to Context) |\n",
        "| **Preferences** | How user likes things presented | Until changed |\n",
        "| **Work History** | Past queries and outcomes | Rolling window (e.g., 90 days) |\n",
        "| **Relationships** | User's team, stakeholders, interests | Updated periodically |\n",
        "\n",
        "## 9.3 Correction Classification\n",
        "\n",
        "When a user corrects system output:\n",
        "\n",
        "| Correction Type | Example | Route To |\n",
        "|-----------------|---------|----------|\n",
        "| **Factual** | \"This column is in schema X\" | Context Layer (after review) |\n",
        "| **Gotcha** | \"Always exclude test accounts\" | Context Layer (after review) |\n",
        "| **Permission** | \"I shouldn't see this PII\" | Rules Layer |\n",
        "| **Preference** | \"I prefer weekly aggregations\" | Memory Layer |\n",
        "\n",
        "## 9.4 Context Poisoning Guardrails\n",
        "\n",
        "The promotion path from Memory (user corrections) to Context (organizational knowledge) creates a potential vector for \"context poisoning\" — where incorrect or malicious corrections could degrade system accuracy for everyone.\n",
        "\n",
        "### Four-Stage Correction Promotion\n",
        "\n",
        "```\n",
        "┌─────────────┐    ┌─────────────┐    ┌─────────────────┐    ┌─────────────┐\n",
        "│   CAPTURE   │ →  │  LOCALIZE   │ →  │  CANDIDATE GEN  │ →  │  AIR GAP    │\n",
        "│             │    │             │    │                 │    │             │\n",
        "│ User makes  │    │ Applied to  │    │ Consensus       │    │ Human       │\n",
        "│ correction  │    │ Personal    │    │ detection       │    │ Stewardship │\n",
        "│             │    │ Memory ONLY │    │ triggers flag   │    │ required    │\n",
        "└─────────────┘    └─────────────┘    └─────────────────┘    └─────────────┘\n",
        "```\n",
        "\n",
        "### Stage 1: Capture\n",
        "\n",
        "When a user corrects the system:\n",
        "- Correction is recorded with full context (original query, original answer, correction, user role)\n",
        "- No immediate action beyond acknowledgment\n",
        "\n",
        "### Stage 2: Localize\n",
        "\n",
        "The correction is applied **ONLY** to that specific user's Personal Memory:\n",
        "- The correcting user benefits immediately\n",
        "- Other users are **never affected automatically**\n",
        "- This is a strict isolation boundary\n",
        "\n",
        "### Stage 3: Aggregated Candidate Generation\n",
        "\n",
        "The system monitors for **Consensus Signals** across users:\n",
        "\n",
        "```yaml\n",
        "consensus_rule:\n",
        "  trigger: \"semantic_similarity\"\n",
        "  conditions:\n",
        "    - distinct_users: \">3\"\n",
        "    - user_role_filter: [\"Senior\", \"Lead\", \"Principal\", \"Manager\"]\n",
        "    - correction_domain: \"same\"  # e.g., all corrections about \"Churn\"\n",
        "    - semantic_similarity: \">0.85\"  # Corrections mean the same thing\n",
        "  action: \"flag_as_context_candidate\"\n",
        "```\n",
        "\n",
        "**Example trigger:** \"If > 3 distinct users with 'Senior' roles make the same semantic correction regarding 'Churn', flag this as a Context Candidate.\"\n",
        "\n",
        "**Why role filtering?** Senior roles have more domain expertise. Corrections from experienced analysts carry more signal than corrections from new users who may be learning.\n",
        "\n",
        "### Stage 4: The \"Air Gap\" (Human Stewardship)\n",
        "\n",
        "Context Candidates **never auto-promote**. There is always a human in the loop.\n",
        "\n",
        "| Step | Action | Owner |\n",
        "|------|--------|-------|\n",
        "| **Queue** | Context Candidate appears in review queue (JIRA ticket or dashboard) | System |\n",
        "| **Review** | Data Steward reviews the candidate correction | Analytics Engineer |\n",
        "| **Verify** | Steward validates against Data Dictionary / dbt manifest | Analytics Engineer |\n",
        "| **Promote** | If valid, Steward submits PR to `analytics-context` repo | Analytics Engineer |\n",
        "| **Merge** | PR reviewed and merged following standard process | Team |\n",
        "\n",
        "```\n",
        "Context Candidate → JIRA Ticket → Steward Review → Validate vs dbt → PR → Merge → Context Layer\n",
        "                                       │\n",
        "                                       └── REJECT if invalid (with reason logged)\n",
        "```\n",
        "\n",
        "### Configuration\n",
        "\n",
        "| Parameter | Default | Description |\n",
        "|-----------|---------|-------------|\n",
        "| `distinct_user_threshold` | 3 | Minimum distinct users to trigger candidate |\n",
        "| `role_filter` | `[\"Senior\", \"Lead\", \"Principal\", \"Manager\"]` | Roles whose corrections trigger consensus |\n",
        "| `semantic_similarity_threshold` | 0.85 | How similar corrections must be to count as \"same\" |\n",
        "| `approval_required` | Always (non-configurable) | Human review is mandatory |\n",
        "| `promotion_mechanism` | Pull Request | How corrections enter Context Layer |\n",
        "\n",
        "### Why This Architecture?\n",
        "\n",
        "| Risk | Mitigation |\n",
        "|------|------------|\n",
        "| Single malicious user poisons context | Localization + consensus threshold |\n",
        "| Multiple confused users create false consensus | Role filtering (senior roles only) |\n",
        "| Valid corrections blocked by bureaucracy | Automated candidate detection reduces manual triage |\n",
        "| Steward rubber-stamps without checking | Validation against dbt manifest required |\n",
        "| Steward unavailable creates bottleneck | Queue visible to multiple stewards |\n",
        "\n",
        "**Key principle:** A single user — even a malicious one — cannot define `revenue = cost` for the entire organization. The air gap ensures all organizational knowledge changes are deliberate and verified.\n",
        "\n",
        "---\n",
        "\n",
        "# 10. Governance & Ownership\n",
        "\n",
        "## 10.1 Component Ownership\n",
        "\n",
        "| Component | Owner | Accountability |\n",
        "|-----------|-------|----------------|\n",
        "| Context Layer | Data Platform | Accuracy of entity definitions |\n",
        "| Rules Layer | Platform Lead | Permission correctness, autonomy calibration |\n",
        "| Memory Layer | Platform Lead | Learning effectiveness |\n",
        "| Orchestration | Platform Lead | Request handling reliability |\n",
        "| Error Likelihood | Data Science | Factor calibration |\n",
        "| Evaluation | Analytics Lead | Eval coverage and quality |\n",
        "\n",
        "## 10.2 Change Management\n",
        "\n",
        "Interface changes require:\n",
        "1. Proposal with rationale\n",
        "2. Review with dependent component owners\n",
        "3. Versioning\n",
        "4. Migration timeline for deprecated interfaces\n",
        "\n",
        "---\n",
        "\n",
        "# 11. Physical Architecture & Repository Strategy\n",
        "\n",
        "## 11.1 Why This Section Exists\n",
        "\n",
        "Sections 2-10 define **logical architecture** (Context, Rules, Memory, Orchestration, Evals).  \n",
        "This section defines **physical architecture**: where components live, how they are deployed, and how they are versioned.\n",
        "\n",
        "## 11.2 Repository Strategy (Recommended)\n",
        "\n",
        "### Decision: Dedicated Platform Repository\n",
        "\n",
        "Use a dedicated repository for the conversational analytics platform:\n",
        "\n",
        "- **Recommended repo name:** `conversational-analytics-platform`\n",
        "- **Ownership:** Data Platform (primary), Analytics Engineering + Data Science (reviewers)\n",
        "- **Release cadence:** Independent from dbt model release cadence\n",
        "\n",
        "### Relationship to Existing Repositories\n",
        "\n",
        "| Repository | Role | Source of Truth |\n",
        "|------------|------|-----------------|\n",
        "| `dbt` | Data transformations, tests, contracts, metadata artifacts | SQL logic and model contracts |\n",
        "| `looker` | BI semantic/explore layer | BI serving and field presentation |\n",
        "| `conversational-analytics-platform` | Orchestration, context retrieval, rules, memory, evals | Conversational runtime behavior |\n",
        "\n",
        "**Rationale:** Keep runtime services and eval pipelines decoupled from analytics transformation code. This enables cleaner ownership, faster iteration, and clearer incident boundaries.\n",
        "\n",
        "## 11.3 Canonical Repository Structure\n",
        "\n",
        "```text\n",
        "conversational-analytics-platform/\n",
        "  README.md\n",
        "  docs/\n",
        "    architecture/\n",
        "      system-overview.md\n",
        "      deployment-topology.md\n",
        "      interface-contracts.md\n",
        "    adr/\n",
        "  services/\n",
        "    api-gateway/\n",
        "    orchestrator/\n",
        "    context-service/\n",
        "    rules-service/\n",
        "    memory-service/\n",
        "    evaluation-service/\n",
        "    execution-gateway/\n",
        "  packages/\n",
        "    contracts/\n",
        "    risk-engine/\n",
        "    telemetry/\n",
        "    authz/\n",
        "  context/\n",
        "    domains/\n",
        "      product/\n",
        "      growth/\n",
        "      finance/\n",
        "      revenue/\n",
        "      marketing/\n",
        "    entities/\n",
        "    metrics/\n",
        "    gotchas/\n",
        "    join-paths/\n",
        "    registry.yaml\n",
        "  evals/\n",
        "    datasets/\n",
        "      golden-queries/\n",
        "    suites/\n",
        "      query-level/\n",
        "      component-level/\n",
        "      system-level/\n",
        "    reports/\n",
        "  configs/\n",
        "    environments/\n",
        "      dev.yaml\n",
        "      staging.yaml\n",
        "      prod.yaml\n",
        "    rules/\n",
        "      autonomy.yaml\n",
        "      escalation.yaml\n",
        "  infra/\n",
        "    terraform/\n",
        "    pipelines/\n",
        "      ci/\n",
        "      cd/\n",
        "  scripts/\n",
        "    sync_dbt_metadata.py\n",
        "    sync_looker_metadata.py\n",
        "  tests/\n",
        "    unit/\n",
        "    integration/\n",
        "    contract/\n",
        "    e2e/\n",
        "  .github/\n",
        "    workflows/\n",
        "```\n",
        "\n",
        "## 11.4 Component-to-Folder Mapping\n",
        "\n",
        "| PRD Component | Runtime/Code Location |\n",
        "|---------------|-----------------------|\n",
        "| Context Layer | `context/` + `services/context-service/` |\n",
        "| Rules Layer | `configs/rules/` + `services/rules-service/` |\n",
        "| Memory Layer | `services/memory-service/` |\n",
        "| Orchestration Layer | `services/orchestrator/` |\n",
        "| Error Likelihood Engine | `packages/risk-engine/` |\n",
        "| Execution & Validation | `services/execution-gateway/` |\n",
        "| Evaluation Framework | `services/evaluation-service/` + `evals/` |\n",
        "| Interface Specifications | `packages/contracts/` |\n",
        "\n",
        "## 11.5 Stage 1 Deployment Boundaries\n",
        "\n",
        "Stage 1 must enforce these boundaries in implementation:\n",
        "\n",
        "1. **Read-only execution only:** `execution-gateway` accepts only SELECT queries\n",
        "2. **Schema whitelist enforcement:** query execution scoped by user RBAC\n",
        "3. **Audit logging required:** all requests and outcomes logged\n",
        "4. **Feature-flag Stage 2 capabilities:** keep scaffolding disabled in production\n",
        "\n",
        "## 11.6 Repo Split Option (Future)\n",
        "\n",
        "The recommended default is one dedicated platform repo.  \n",
        "If governance complexity grows, split context into a separate repo:\n",
        "\n",
        "- `conversational-analytics-platform` (runtime + orchestration + evals)\n",
        "- `analytics-context` (governed shared context artifacts)\n",
        "\n",
        "Only split when needed; start with one platform repo to reduce operational complexity.\n",
        "\n",
        "---\n",
        "\n",
        "# PART B: IMPLEMENTATION DETAILS\n",
        "\n",
        "---\n",
        "\n",
        "# Appendix A: Interface Specifications\n",
        "\n",
        "## A.1 Context Layer Interface\n",
        "\n",
        "```yaml\n",
        "# INPUT: Context Request\n",
        "context_request:\n",
        "  query: string              # Natural language question\n",
        "  domain_hint: string?       # Optional domain\n",
        "  actor_id: string?          # For personalized context\n",
        "  session_id: string?        # For multi-turn context\n",
        "\n",
        "# OUTPUT: Context Response\n",
        "context_response:\n",
        "  matched_entities:\n",
        "    - entity_name: string\n",
        "      relevance_score: float\n",
        "      columns: Column[]\n",
        "      gotchas: Gotcha[]\n",
        "      join_paths: JoinPath[]\n",
        "  domain_guide: DomainGuide?\n",
        "  business_context: BusinessContext?  # Stage 2\n",
        "  disambiguation_needed: boolean\n",
        "  disambiguation_questions: Question[]?\n",
        "  error_likelihood_factors:\n",
        "    complexity: float\n",
        "    source_risk: float\n",
        "    novelty: float\n",
        "    ambiguity: float\n",
        "```\n",
        "\n",
        "## A.2 Rules Layer Interface\n",
        "\n",
        "```yaml\n",
        "# INPUT: Authorization Request\n",
        "auth_request:\n",
        "  actor:\n",
        "    id: string\n",
        "    type: enum[human, agent]\n",
        "    role: string\n",
        "    risk_tolerance: RiskTolerance?\n",
        "  action:\n",
        "    type: enum[query, modify, recommend]\n",
        "    target_schemas: string[]\n",
        "  risk:\n",
        "    error_likelihood: float\n",
        "    expected_cost: float?\n",
        "\n",
        "# OUTPUT: Authorization Response\n",
        "auth_response:\n",
        "  decision: enum[PROCEED, NOTIFY, CONFIRM, RECOMMEND, BLOCK]\n",
        "  autonomy_level: int\n",
        "  rationale: string\n",
        "  escalation_path: Actor[]?\n",
        "```\n",
        "\n",
        "## A.3 Memory Layer Interface\n",
        "\n",
        "```yaml\n",
        "# RETAIN: Store memory\n",
        "retain_request:\n",
        "  memory_type: enum[correction, preference, experience]\n",
        "  content: any\n",
        "  actor_id: string\n",
        "  session_id: string?\n",
        "\n",
        "# RECALL: Retrieve memories\n",
        "recall_request:\n",
        "  actor_id: string\n",
        "  context: string[]  # Relevant entities/domains\n",
        "  \n",
        "recall_response:\n",
        "  memories:\n",
        "    - type: string\n",
        "      content: any\n",
        "      relevance: float\n",
        "```\n",
        "\n",
        "## A.4 Execution Layer Interface\n",
        "\n",
        "```yaml\n",
        "# INPUT: Execution Request\n",
        "execution_request:\n",
        "  request_id: string\n",
        "  sql: string\n",
        "  schema_whitelist: string[]  # Injected based on user RBAC\n",
        "\n",
        "# OUTPUT: Execution Response\n",
        "execution_response:\n",
        "  request_id: string\n",
        "  status: enum[success, rejected, error]\n",
        "  rejection_reason: string?   # e.g., \"Non-SELECT query rejected\", \"Schema not in whitelist\"\n",
        "  \n",
        "  validation:\n",
        "    sql_type: string          # SELECT, INSERT, UPDATE, etc.\n",
        "    is_allowed: boolean       # Stage 1: only SELECT allowed\n",
        "    schemas_referenced: string[]\n",
        "    schemas_blocked: string[]\n",
        "  \n",
        "  plan:                       # EXPLAIN results (only if validation passed)\n",
        "    estimated_scan_gb: float\n",
        "    estimated_runtime_ms: int\n",
        "    estimated_rows: int\n",
        "    warnings: string[]\n",
        "  \n",
        "  results:                    # Only if execution succeeded\n",
        "    columns: Column[]\n",
        "    rows: Row[]\n",
        "    row_count: int\n",
        "    truncated: boolean\n",
        "```\n",
        "\n",
        "## A.5 Orchestration Interface\n",
        "\n",
        "```yaml\n",
        "# Analytics Request\n",
        "analytics_request:\n",
        "  request_id: string\n",
        "  actor:\n",
        "    id: string\n",
        "    type: enum[human, agent]\n",
        "  query:\n",
        "    natural_language: string\n",
        "  preferences:\n",
        "    autonomy_override: int?  # User can request specific level\n",
        "    criticality: enum[low, normal, high]?\n",
        "\n",
        "# Analytics Response\n",
        "analytics_response:\n",
        "  request_id: string\n",
        "  status: enum[completed, pending_acceptance, needs_disambiguation, blocked]\n",
        "  result:\n",
        "    sql: string?\n",
        "    data: any?\n",
        "    confidence: float\n",
        "    caveats: string[]\n",
        "  acceptance:\n",
        "    required: boolean\n",
        "    timeout_minutes: int?\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# Appendix B: Data Schemas\n",
        "\n",
        "## B.1 Query Log Schema\n",
        "\n",
        "```yaml\n",
        "query_log:\n",
        "  log_id: string\n",
        "  timestamp: datetime\n",
        "  \n",
        "  request:\n",
        "    request_id: string\n",
        "    actor_id: string\n",
        "    natural_language: string\n",
        "    session_id: string\n",
        "    stated_criticality: enum[low, normal, high]?\n",
        "  \n",
        "  context:\n",
        "    matched_entities: string[]\n",
        "    domain: string\n",
        "    routing_confidence: float\n",
        "  \n",
        "  risk:\n",
        "    error_likelihood: float\n",
        "    expected_cost: float?\n",
        "    factors:\n",
        "      complexity: float\n",
        "      source_risk: float\n",
        "      novelty: float\n",
        "      ambiguity: float\n",
        "  \n",
        "  execution:\n",
        "    autonomy_level: int\n",
        "    generated_sql: string\n",
        "    execution_time_ms: int\n",
        "  \n",
        "  outcome:\n",
        "    user_accepted: boolean\n",
        "    feedback: enum[positive, negative, none]?\n",
        "    correction_made: boolean\n",
        "    correction_type: string?\n",
        "```\n",
        "\n",
        "## B.2 Correction Schema\n",
        "\n",
        "```yaml\n",
        "correction:\n",
        "  id: string\n",
        "  timestamp: datetime\n",
        "  actor_id: string\n",
        "  actor_role: string               # For consensus role filtering\n",
        "  source_request_id: string\n",
        "  \n",
        "  correction_type: enum[factual, gotcha, permission, preference]\n",
        "  correction_domain: string        # e.g., \"Churn\", \"Revenue\", \"User\"\n",
        "  \n",
        "  original:\n",
        "    content: any\n",
        "  corrected:\n",
        "    content: any\n",
        "  \n",
        "  embedding: vector                # For semantic similarity matching\n",
        "  \n",
        "  routing:\n",
        "    target_layer: enum[context, rules, memory]\n",
        "    stage: enum[captured, localized, candidate, promoted, rejected]\n",
        "    \n",
        "  # Populated when stage = \"localized\"\n",
        "  personal_memory:\n",
        "    applied_to_user: boolean\n",
        "    applied_at: datetime\n",
        "    \n",
        "  # Populated when stage = \"candidate\"\n",
        "  consensus:\n",
        "    similar_corrections: string[]  # IDs of similar corrections\n",
        "    distinct_users: int\n",
        "    triggered_at: datetime\n",
        "    jira_ticket: string?\n",
        "    \n",
        "  # Populated when stage = \"promoted\" or \"rejected\"\n",
        "  stewardship:\n",
        "    reviewed_by: string\n",
        "    reviewed_at: datetime\n",
        "    decision: enum[approved, rejected]\n",
        "    rejection_reason: string?\n",
        "    pull_request_url: string?\n",
        "    merged_at: datetime?\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# Appendix C: Agent Instructions\n",
        "\n",
        "> **This appendix provides explicit instructions for AI agents operating within this system.**\n",
        "\n",
        "## C.1 Context for AI Agents\n",
        "\n",
        "You are operating within a **compound AI system** for conversational analytics. Your role is defined by the **Rules Layer** and your actions are logged to the **Memory Layer**.\n",
        "\n",
        "### Operating Principles\n",
        "\n",
        "1. **ALWAYS** check error likelihood before proceeding\n",
        "2. **ALWAYS** respect autonomy level decisions\n",
        "3. **ALWAYS** log your actions for auditability\n",
        "4. **ALWAYS** obtain user acceptance before closing a request\n",
        "5. **NEVER** bypass disambiguation when error likelihood ≥ 0.5\n",
        "6. **NEVER** auto-close requests at Level 1-3 without user confirmation\n",
        "\n",
        "### Stage 1 Operational Constraints\n",
        "\n",
        "**Read-Only:** Stage 1 only permits SELECT queries. Any non-SELECT SQL is rejected at the Execution Layer.\n",
        "\n",
        "**Schema Whitelist:** The Orchestration Layer injects a `schema_whitelist` based on user RBAC. The Execution Layer rejects queries referencing schemas outside this list.\n",
        "\n",
        "**Audit Logging:** All queries are logged with full context for traceability.\n",
        "\n",
        "## C.2 Decision Tree (Stage 1: Read-Only)\n",
        "\n",
        "```\n",
        "START\n",
        "  │\n",
        "  ▼\n",
        "Parse user query\n",
        "  │\n",
        "  ▼\n",
        "Generate SQL\n",
        "  │\n",
        "  ├── If NOT SELECT query → REJECT immediately\n",
        "  │     Response: \"Write operations not supported in Stage 1.\"\n",
        "  │     END\n",
        "  │\n",
        "  ▼\n",
        "Call Context Layer → Get matched entities\n",
        "  │\n",
        "  ▼\n",
        "Call Error Likelihood Engine → Get risk score\n",
        "  │\n",
        "  ▼\n",
        "Check user risk tolerance and stated criticality\n",
        "  │\n",
        "  ▼\n",
        "Calculate combined risk = error_likelihood × expected_cost\n",
        "  │\n",
        "  ▼\n",
        "Determine autonomy level\n",
        "  │\n",
        "  ├── If Level 5 (Full Autonomy)\n",
        "  │     │\n",
        "  │     ▼\n",
        "  │   Run EXPLAIN → Check resource cost\n",
        "  │     ├── If resources OK → Execute\n",
        "  │     └── If resources HIGH → Elevate to Level 3\n",
        "  │   Present Results\n",
        "  │   Wait for implicit acceptance or timeout (24h)\n",
        "  │   Close request\n",
        "  │\n",
        "  ├── If Level 4 (Notify)\n",
        "  │     │\n",
        "  │     ▼\n",
        "  │   Run EXPLAIN → Check resource cost\n",
        "  │     ├── If resources OK → Execute\n",
        "  │     └── If resources HIGH → Elevate to Level 3\n",
        "  │   Present Results, Notify stakeholders\n",
        "  │   Wait for implicit acceptance or timeout (48h)\n",
        "  │   Close request\n",
        "  │\n",
        "  ├── If Level 3 (Confirm)\n",
        "  │     │\n",
        "  │     ▼\n",
        "  │   Run EXPLAIN → Check resource cost\n",
        "  │     ├── If resources OK → Execute\n",
        "  │     └── If resources HIGH → Warn user, request confirmation\n",
        "  │   Present Results\n",
        "  │   Request explicit user acceptance\n",
        "  │   IF user accepts → Close request\n",
        "  │   IF user revises → Loop back to parse revised query\n",
        "  │   IF timeout (72h) → Mark as Abandoned, notify user\n",
        "  │\n",
        "  ├── If Level 2 (Recommend)\n",
        "  │     │\n",
        "  │     ▼\n",
        "  │   Show SQL recommendation (do not execute)\n",
        "  │   Run EXPLAIN → Show estimated cost\n",
        "  │   Present recommendation with rationale\n",
        "  │   User decides whether to execute\n",
        "  │   IF timeout (7 days) → Expire recommendation, notify user\n",
        "  │\n",
        "  └── If Level 1 (Human Only)\n",
        "        │\n",
        "        ▼\n",
        "      Flag for human handling\n",
        "      Explain why automation is inappropriate\n",
        "      No timeout (remains open)\n",
        "```\n",
        "\n",
        "## C.3 Handling Disambiguation\n",
        "\n",
        "When ambiguity score is high (≥ 0.5):\n",
        "\n",
        "```yaml\n",
        "# 1. Identify ambiguous elements\n",
        "ambiguous_elements:\n",
        "  - type: column\n",
        "    options: [\"user.user_id\", \"activity.user_id\"]\n",
        "    question: \"Which user_id do you mean?\"\n",
        "  - type: metric\n",
        "    options: [\"ARR (annual)\", \"MRR (monthly)\"]\n",
        "    question: \"Which revenue metric?\"\n",
        "\n",
        "# 2. Present structured questions\n",
        "response: |\n",
        "  I need to clarify a few things:\n",
        "  \n",
        "  1. Multiple columns match 'user_id'. Which should I use?\n",
        "     a) user.user_id - Primary user identifier\n",
        "     b) activity.user_id - Activity-specific ID\n",
        "  \n",
        "  2. Which revenue metric do you need?\n",
        "     a) ARR (Annual Recurring Revenue)\n",
        "     b) MRR (Monthly Recurring Revenue)\n",
        "\n",
        "# 3. Wait for user response\n",
        "# 4. Recalculate error likelihood with clarified scope\n",
        "# 5. Proceed when ambiguity score < 0.5\n",
        "```\n",
        "\n",
        "## C.4 Handling Corrections\n",
        "\n",
        "```yaml\n",
        "# When user provides correction:\n",
        "\n",
        "# 1. Acknowledge\n",
        "response: \"I understand. Let me update my understanding.\"\n",
        "\n",
        "# 2. Classify\n",
        "correction_type = classify(correction)\n",
        "correction_domain = extract_domain(correction)  # e.g., \"Churn\", \"Revenue\"\n",
        "\n",
        "# 3. Route based on type\n",
        "if correction_type in [factual, gotcha]:\n",
        "  # CAPTURE: Record correction with full context\n",
        "  correction = create_correction(\n",
        "    type: correction_type,\n",
        "    domain: correction_domain,\n",
        "    actor_role: user.role,\n",
        "    embedding: embed(correction.content)\n",
        "  )\n",
        "  \n",
        "  # LOCALIZE: Apply to Personal Memory ONLY\n",
        "  personal_memory.add(correction)\n",
        "  correction.stage = \"localized\"\n",
        "  \n",
        "  # Inform user of the process\n",
        "  response: |\n",
        "    I've applied this correction to your personal context — it will\n",
        "    improve my answers for you immediately.\n",
        "    \n",
        "    If multiple senior analysts make similar corrections, this may be\n",
        "    flagged for review to update the shared knowledge base.\n",
        "  \n",
        "if correction_type == preference:\n",
        "  # Preferences go directly to Memory Layer (no consensus needed)\n",
        "  action: Store directly in Memory Layer\n",
        "  memory: Update user preferences\n",
        "  response: \"I've noted your preference and will apply it to future queries.\"\n",
        "  \n",
        "if correction_type == permission:\n",
        "  # Security issues bypass the normal flow\n",
        "  action: Flag for immediate Rules Layer review\n",
        "  log: Security event\n",
        "  response: \"I've flagged this as a permission issue for immediate review.\"\n",
        "\n",
        "# 4. Background: Consensus Detection (runs asynchronously)\n",
        "# System checks if this correction triggers a consensus signal:\n",
        "#\n",
        "# IF (\n",
        "#   count(similar_corrections where actor_role in SENIOR_ROLES) > 3\n",
        "#   AND semantic_similarity > 0.85\n",
        "# ) THEN:\n",
        "#   correction.stage = \"candidate\"\n",
        "#   create_jira_ticket(correction)\n",
        "#   notify_stewards()\n",
        "```\n",
        "\n",
        "## C.5 Multi-Turn Context\n",
        "\n",
        "```yaml\n",
        "# Maintain session state\n",
        "session:\n",
        "  entities_discussed: []      # Accumulate\n",
        "  filters_established: []     # Carry forward\n",
        "  corrections_applied: []     # Apply to all queries\n",
        "  disambiguation_choices: []  # Remember preferences\n",
        "\n",
        "# On each turn:\n",
        "1. Load session context\n",
        "2. Apply accumulated filters and corrections\n",
        "3. Boost relevance for previously discussed entities\n",
        "4. Process new query\n",
        "5. Update session context\n",
        "6. Persist to Memory Layer\n",
        "\n",
        "# Referential phrases:\n",
        "# \"same as before\" → use previous parameters\n",
        "# \"but for Q2\" → modify previous query\n",
        "# \"actually, I meant...\" → correction to previous query\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# Appendix D: Implementation Roadmap\n",
        "\n",
        "## Phase 1: Foundation (Weeks 1-4)\n",
        "\n",
        "| Task | Owner | Priority |\n",
        "|------|-------|----------|\n",
        "| Finalize PRD with architect input | Koen | P1 |\n",
        "| Design QueryLog schema | Koen | P1 |\n",
        "| Implement logging in get_query_context | Felipe | P1 |\n",
        "| Add Product Analytics domain guide | Analytics | P1 |\n",
        "| Prototype error likelihood calculation | Koen | P2 |\n",
        "\n",
        "## Phase 2: Core Components (Weeks 5-8)\n",
        "\n",
        "| Task | Owner | Priority |\n",
        "|------|-------|----------|\n",
        "| Implement rules/roles.yaml | Platform | P1 |\n",
        "| Implement rules/autonomy.yaml | Platform | P1 |\n",
        "| Add user feedback collection | Felipe | P1 |\n",
        "| Implement memory/corrections.jsonl | Platform | P2 |\n",
        "\n",
        "## Phase 3: Orchestration (Weeks 9-12)\n",
        "\n",
        "| Task | Owner | Priority |\n",
        "|------|-------|----------|\n",
        "| Implement orchestration state machine | Platform | P1 |\n",
        "| Add user acceptance flow | Platform | P1 |\n",
        "| Implement disambiguation UI | Frontend | P2 |\n",
        "\n",
        "## Phase 4: Calibration (Weeks 13-16)\n",
        "\n",
        "| Task | Owner | Priority |\n",
        "|------|-------|----------|\n",
        "| Build ground truth dataset | Analytics | P1 |\n",
        "| Implement error likelihood validation | Data Science | P2 |\n",
        "| Calibrate autonomy thresholds | Data Science | P2 |\n",
        "\n",
        "---\n",
        "\n",
        "# Document History\n",
        "\n",
        "| Date | Version | Change | Author |\n",
        "|------|---------|--------|--------|\n",
        "| 2026-02-17 | 1.0 | Initial draft | Koen Rutten |\n",
        "| 2026-02-17 | 1.1 | Restructured per feedback: separated concepts from implementation; clarified Context vs Memory; added staged approach; added expected cost to risk; clarified autonomy levels; added user acceptance requirement; established eval hierarchy | Koen Rutten |\n",
        "| 2026-02-17 | 1.2 | Architecture review: Privacy architecture, CI/CD context refresh, policy triggers, improved error likelihood computation, PLAN stage, timeout handling, context poisoning guardrails, four-stage correction promotion | Koen Rutten |\n",
        "| 2026-02-17 | 1.3 | Stage boundary clarification: Stage 1 read-only (SELECT only hard gate); Stage 2 scope defined; Replaced disambiguation rate with quality metrics (clarification precision, post-clarification acceptance, incorrect-first-answer rate); Formalized weight calibration plan (bootstrap + monthly recalibration); Added logprob availability fallback for ambiguity; Reduced privacy/security narrative emphasis; Retained minimal operational safeguards (schema whitelist, query allowlist, audit logging) | Koen Rutten |\n",
        "| 2026-02-17 | 1.4 | Added physical architecture and repository strategy section: dedicated platform repo recommendation, canonical repo structure, component-to-folder mapping, Stage 1 deployment boundaries, and future repo split option | Koen Rutten |\n",
        "\n",
        "---\n",
        "\n",
        "# Approval\n",
        "\n",
        "| Role | Name | Date | Signature |\n",
        "|------|------|------|-----------|\n",
        "| Author | Koen Rutten | 2026-02-17 | ✓ |\n",
        "| Technical Review | Larissa / Rebecca | Pending | |\n",
        "| Business Review | Dima Potapov | Pending | |\n",
        "\n",
        "---\n",
        "\n",
        "*This document should be treated as a living specification. Updates should be proposed via PR with review from affected component owners.*\n"
      ],
      "metadata": {
        "id": "uKKAOvnqctEg"
      }
    }
  ]
}